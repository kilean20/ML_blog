{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "This note is a section by section summary of the [paper](https://arxiv.org/abs/1406.2661)  based on personal understanding. Some personal remarks appear at the end of the note."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "- generative model $G_\\theta:z\\rightarrow x$\n",
    "    - where $x\\in p_{g,\\theta}$ which we want to train to $p_{data}$\n",
    "    - and $z\\in p_z$ which is a prior.\n",
    "- discriminative model: $D_\\phi:x\\rightarrow u$  \n",
    "    - where $u\\in(0,1)$ representing *False* and *True*\n",
    "- with NN model of $G_\\theta$ and $D_\\phi$, they form *adversarial nets*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Related work\n",
    "\n",
    "Most work on deep generative models focused on models that provided a parametric specification of a probability distributions. But GAN does not assume any distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adversarial nets\n",
    "\n",
    "$D$ and $G$ play the following two-player *minimax* game $\\min_\\theta \\max_\\phi V(D_\\phi,G_\\theta)$ where\n",
    "\n",
    "$$\n",
    "V(D_\\phi,G_\\theta) = \\mathbb{E}_{x\\sim p_{data}} [\\log D_\\phi(x)] + \\mathbb{E}_{z\\sim p_z} [\\log (1-D_\\phi(G_\\theta(z)))]\n",
    "$$\n",
    "\n",
    "Optimizing $D$ to completion in the inner loop of training is computationally prohibitive, and on finite datasets would result in overfitting. Instead, we alternate between k steps of optimizing $D$ and one step of optimizing $G$. This results in $D$ being maintained near its optimal solution, so long as $G$ changes slowly enough.\n",
    "\n",
    "\n",
    "#### $\\,$ Algorithm 1 ----------------------------------------------------------------------------------------  \n",
    "\n",
    "$\\quad$**for** epcohs **do**  \n",
    "$\\quad\\quad$  **for** $k$ steps **do**  \n",
    "$\\quad\\quad\\quad$  $m$ sample of $z\\sim p_z$  \n",
    "$\\quad\\quad\\quad$  $m$ sample of data $x\\in p_{data}$  \n",
    "$\\quad\\quad\\quad$  Update $D$ by ascending its stochastic gradient:  \n",
    "$$\\nabla_\\theta \\frac{1}{m} \\sum_i^m \\log D_\\phi(x_i) + \\log (1-D_\\phi(G_\\theta(z_i)))\n",
    "$$\n",
    "$\\quad\\quad$  **end for**  \n",
    "$\\quad\\quad$  $m$ sample of $z\\sim p_z$  \n",
    "$\\quad\\quad$  Update $G$ by descending its stochastic gradient:  \n",
    "$$\n",
    "\\nabla_\\phi \\frac{1}{m} \\sum_i^m  \\log (1-D_\\phi(G_\\theta(z_i)))\n",
    "$$\n",
    "$\\quad\\quad$**end for**  \n",
    "#### ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Theoretical results\n",
    "\n",
    "will Algorithm 1. converge to good estimator of $p_{data}$?\n",
    "\n",
    "#### 4.1. Global Optimzality of $p_g=p_{data}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposition 1.** For $G$ fixed (i.e. $\\theta$ fixed), the optimal $D$ is\n",
    "$$\n",
    "D^*_\\theta(x) = \\frac{p_{data}(x)}{p_{data}(x)+p_{g,\\theta}(x)}\n",
    "$$\n",
    "(note: $D^*_\\theta(x)$ now depends on $\\theta$ not $\\phi$)\n",
    "\n",
    "\n",
    "**proof:** \n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "V(D_\\phi,G_\\theta) &=& \\mathbb{E}_{x\\sim p_{data}} [\\log D_\\phi(x)] + \\mathbb{E}_{z\\sim p_z} [\\log (1-D_\\phi(G_\\theta(z)))] \\\\\n",
    "                   &=& \\int_x p_{data}(x) \\log D_\\phi(x) dx +  \\int_z p_z (z) \\log (1-D_\\phi(G_\\theta(z))) dz\\\\\n",
    "                   &=& \\int_x \\left[ p_{data}(x) \\log D_\\phi(x) +  p_{g,\\theta} (x) \\log (1-D_\\phi(x)) \\right] dx\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "For any $(a,b)\\in \\mathbb{R} \\backslash \\{0,0\\}$, the function $f(x) = a \\log(x) + b \\log(1-x)$ is maximum in $[0,1]$ at $\\frac{a}{a+b}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define** the *max* part of *minmax* game as\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "C(\\theta) &=& \\max_\\phi V(D_\\phi,G_\\theta) \\\\\n",
    "          &=& \\mathbb{E}_{x\\sim p_{data}} [\\log D^*_\\theta(x)] + \\mathbb{E}_{x\\sim p_g} [\\log (1-D^*_\\theta(x))]\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 1.** The global minimum of $C(\\theta)$ is achieved *if and only if* $p_{g,\\theta} = p_{data}$ at which $C(\\theta)=-\\log4$\n",
    "\n",
    "**proof:** $C(\\theta)$ can be re-written by\n",
    "$$\n",
    "C(\\theta) = -\\log 4 + KL\\left(p_{data}| \\frac{p_{data}+p_{g,\\theta}}{2}\\right)  + KL\\left(p_{g,\\theta}| \\frac{p_{data}+p_{g,\\theta}}{2}\\right) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Convergence of Algorithm 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposition 2.** If $G_\\theta$ and $D_\\phi$ have enough capacity, the discriminator is allowed to reach its optimum given $G_\\theta$, then $p_g \\rightarrow p_{data}$\n",
    "\n",
    "In practice, adversarial nets represent a limited family of $p_g$, so the proofs do not apply. However, the excellent performance of NN in practice suggests that they are a reasonable model.\n",
    "\n",
    "Following plots illustrates the convergence given optimal $D^*$ (plots are from the [paper](https://arxiv.org/abs/1406.2661)).\n",
    "\n",
    "<img src=\"GAN_trainG_withOptimumD.png\" width=\"600\"/>\n",
    "\n",
    "*blue dashed*: distribution of $D$, $\\,$ *green solid*: distribution of $p_g$, $\\,$ *black dotted*: distribution of $p_{data}$  \n",
    "(a) before $D$ is optimum. $\\,$ (b) $D=D^*$. $\\,$ (c),(d) $p_g$ is converging to $p_{data}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiments\n",
    "\n",
    "- $G_\\theta$: ReLu, Sigmoid  \n",
    "- $D_\\phi$: Dropout, Maxout \n",
    "    - Maxout: max($w_1 \\cdot x + b_1, \\, w_2 \\cdot x + b_2$). \n",
    "        - advantage : gradient does not saturate\n",
    "        - disadvantage: need two neurons\n",
    "\n",
    "The mean log-likelyhood on samples from test data (MNIST) performed best compared other genertive models (see the paper for details). The likelihood of $p_g$ is estimated by fitting Gaussian Parzen window (a kernel density estimation method) to the samples generated by $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advantages and disadvantages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Advantages\n",
    "    - Generator is not directly exposed to data $\\rightarrow$ parameters does not memorize inputs ($\\rightarrow$ avoid overfit? )\n",
    "    - Can represent sharp or [degenerate](https://en.wikipedia.org/wiki/Degenerate_distribution) disribution ($\\rightarrow$ better quality? )\n",
    "- Disadvantages\n",
    "    - No explicit representation of $p_g$\n",
    "    - Training can be tricky: $G$ vs. $D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Remark\n",
    "Early in learning, when $G$ is poor, $D$ can reject samples with high confidence. Rather than training G to minimize $\\log(1 - D(G(z)))$ we can train $G$ to maximize $\\log D(G(z))$. This objective function results in the\n",
    "same fixed point of the dynamics of $G$ and $D$ but provides much stronger gradients early in learning. See the plot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
