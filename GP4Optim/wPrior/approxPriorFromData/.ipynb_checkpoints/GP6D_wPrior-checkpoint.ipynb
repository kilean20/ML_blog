{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "from copy import deepcopy as copy\n",
    "# np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/kilean20/pyTorchTemplate.git\n",
      "  Cloning https://github.com/kilean20/pyTorchTemplate.git to /tmp/pip-req-build-lfv4hfnq\n",
      "  Running command git clone -q https://github.com/kilean20/pyTorchTemplate.git /tmp/pip-req-build-lfv4hfnq\n",
      "Requirement already satisfied (use --upgrade to upgrade): pyTorchTemplate==0.0.1 from git+https://github.com/kilean20/pyTorchTemplate.git in /global/u1/k/khwang/.local/cori/pytorchv1.4.0/lib/python3.7/site-packages\n",
      "Building wheels for collected packages: pyTorchTemplate\n",
      "  Building wheel for pyTorchTemplate (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyTorchTemplate: filename=pyTorchTemplate-0.0.1-py3-none-any.whl size=6602 sha256=dccf3f4b4c835851b82491a0155d666f132cc2e645c1fe8778f125c875623fce\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-t1f_ttma/wheels/15/b3/6d/10ca0e96789eddf8cbd29d87914215e75608e6930926678261\n",
      "Successfully built pyTorchTemplate\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/kilean20/pyTorchTemplate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/kilean20/pyTorchTemplate.git\n",
      "  Cloning https://github.com/kilean20/pyTorchTemplate.git to /tmp/pip-req-build-28cua3_0\n",
      "  Running command git clone -q https://github.com/kilean20/pyTorchTemplate.git /tmp/pip-req-build-28cua3_0\n",
      "Building wheels for collected packages: pyTorchTemplate\n",
      "  Building wheel for pyTorchTemplate (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyTorchTemplate: filename=pyTorchTemplate-0.0.1-py3-none-any.whl size=6602 sha256=2f34a064c3117e21d25a3ca0e6e626e641271766ba09d63c3b61339187c0005c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-pl47su6f/wheels/15/b3/6d/10ca0e96789eddf8cbd29d87914215e75608e6930926678261\n",
      "Successfully built pyTorchTemplate\n",
      "Installing collected packages: pyTorchTemplate\n",
      "  Attempting uninstall: pyTorchTemplate\n",
      "    Found existing installation: pyTorchTemplate 0.0.1\n",
      "    Uninstalling pyTorchTemplate-0.0.1:\n",
      "      Successfully uninstalled pyTorchTemplate-0.0.1\n",
      "Successfully installed pyTorchTemplate-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/kilean20/pyTorchTemplate.git --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyTorchTemplate as ptt\n",
    "device = ptt.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 6\n",
    "n = 2048  #number of samples\n",
    "nPrior = n*100\n",
    "p = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to fit\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "R &=& |\\boldsymbol{x}| \\\\\n",
    "{f} &=& \\frac{\\sin(4\\pi R)}{4\\pi R}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"The function to predict.\"\"\"\n",
    "    \n",
    "    R = np.sqrt(np.sum(x**2,axis=1)) + 0.0001\n",
    "    return np.sin(4*np.pi*R)/(4*np.pi*R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ((np.random.rand(n,d)-0.5)*2).astype(np.float32)\n",
    "y_train = f(x_train)\n",
    "\n",
    "x_test = ((np.random.rand(n,d)-0.5)*2).astype(np.float32)\n",
    "y_test = f(x_test)\n",
    "\n",
    "x_onAxis = np.zeros([128,d],dtype=np.float32)\n",
    "x_onAxis[:,0] = np.linspace(-1, 1, 128)\n",
    "y_onAxis = f(x_onAxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train,bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GP fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without Prior model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = C(1.0, (2e-2, 10.0)) * RBF(1, (2e-2, 1.0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.00013711432662888434, -9.63713955890455e-05)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.score(x_train, y_train), gp.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.fit(x_train, y_train)\n",
    "gp.kernel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.score(x_train, y_train), gp.score(x_test, y_test)  \n",
    "# score over test data after train can become even worse when train data is not enough !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, sigma = gp.predict(x_onAxis, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(x_onAxis[:,0],y_onAxis ,'k', label='Ground Truth')\n",
    "ax.plot(x_onAxis[:,0],y_pred,   'b-', label='Prediction')\n",
    "ax.fill_between(x_onAxis[:,0], y_pred- 1.96 * sigma,\n",
    "                               y_pred+ 1.96 * sigma, \n",
    "                label='95% confidence interval', color='C0', alpha=.5, )\n",
    "\n",
    "plt.title('1D slice view of '+str(d)+'D problem')\n",
    "plt.xlabel(r'$x_0$')\n",
    "plt.ylabel(r'$f(x)$')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-0.4,1.2)\n",
    "plt.xticks([-1,-0.5,0,0.5,1])\n",
    "plt.savefig('GP'+str(d)+'D_'+str(n)+'sample.png',dpi=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with Prior model\n",
    "Model true prior\n",
    "$$\n",
    "f_{0}(\\boldsymbol{x})=f(\\boldsymbol{x}) + a(\\boldsymbol{x})\\sin\\phi(\\boldsymbol{x}) + b(\\boldsymbol{x})\n",
    "$$\n",
    "\n",
    "where $a(\\boldsymbol{x})$, $\\phi(\\boldsymbol{x})$ and $b(\\boldsymbol{x})$ are modeled using randomized neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_func = torch.nn.Sequential(torch.nn.Linear(d,32),\n",
    "                               torch.nn.CELU(),\n",
    "                               torch.nn.Linear(32,32),\n",
    "                               torch.nn.CELU(),\n",
    "                               torch.nn.Linear(32,1))\n",
    "\n",
    "phase_func = torch.nn.Sequential(torch.nn.Linear(d,32),\n",
    "                                 torch.nn.CELU(),\n",
    "                                 torch.nn.Linear(32,32),\n",
    "                                 torch.nn.CELU(),\n",
    "                                 torch.nn.Linear(32,1))\n",
    "\n",
    "bias_func = torch.nn.Sequential(torch.nn.Linear(d,32),\n",
    "                                torch.nn.CELU(),\n",
    "                                torch.nn.Linear(32,32),\n",
    "                                torch.nn.CELU(),\n",
    "                                torch.nn.Linear(32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()['0.weight'].copy_(model.state_dict()['0.weight']);\n",
    "# model.state_dict()['0.bias'].copy_(model.state_dict()['0.bias']);\n",
    "# model.state_dict()['2.weight'].copy_(model.state_dict()['2.weight']);\n",
    "# model.state_dict()['2.bias'].copy_(model.state_dict()['2.bias']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f0(x):\n",
    "    \"\"\"The approximate function to predict.\"\"\"\n",
    "    f0 = f(x)\n",
    "    amp = amp_func(torch.Tensor(2*x+2)).detach().numpy().ravel()\n",
    "    phase = phase_func(torch.Tensor(10*x+2)).detach().numpy().ravel()\n",
    "    bias = bias_func(torch.Tensor(2*x+2)).detach().numpy().ravel()\n",
    "    \n",
    "    return f0+0.7*(0.5*f0+amp)*np.sin(5*phase)-0.7*bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,4))\n",
    "\n",
    "plt.plot(x_onAxis[:,0],y_onAxis ,'k' , label='Ground Truth')\n",
    "plt.plot(x_onAxis[:,0],f0(x_onAxis),'r', label='Prior')\n",
    "plt.plot(x_onAxis[:,0],y_onAxis-f0(x_onAxis),'b:', label='Difference',alpha=0.5)\n",
    "\n",
    "\n",
    "plt.title('1D slice view of Prior')\n",
    "plt.xlabel(r'$x_0$')\n",
    "plt.ylabel(r'$f(x)$')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-0.4,1.2)\n",
    "plt.xticks([-1,-0.5,0,0.5,1])\n",
    "plt.savefig('Prior_'+str(d)+'D_SliceView.png',dpi=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using rough estimated data, we build the approximate prior close to the true prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xPrior_train = ((np.random.rand(nPrior,d)-0.5)*2).astype(np.float32)\n",
    "yPrior_train = f0(xPrior_train).reshape(-1,1).astype(np.float32)\n",
    "train_data_loader = torch.utils.data.DataLoader(list(zip(xPrior_train,yPrior_train)),batch_size=128*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(yPrior_train,bins=100);\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('count')\n",
    "plt.title('train data histogram of prior')\n",
    "# plt.xlim(yPrior_train.min(),yPrior_train.max())\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig('prior_train_data_histo_'+str(d)+'D_'+str(nPrior)+'sample.png',dpi=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,criterion,test_data_loader):\n",
    "  model.eval()\n",
    "  loss = 0 \n",
    "  for x, y in test_data_loader:\n",
    "    x = x.to(device)\n",
    "    y_pred = model(x)\n",
    "    loss += criterion(y_pred, y.to(device)).item()\n",
    "  return loss/len(test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsource  = 6\n",
    "old_best_loss = 1\n",
    "for i in range(10):\n",
    "  model = ptt.resFCNN([d,256,256,1], torch.nn.CELU(inplace=True))\n",
    "  mode,hist = ptt.train_supervised(model,1.0e-2,10,\n",
    "                                  train_data_loader,\n",
    "                                  optimizer=torch.optim.Adam,\n",
    "#                                   optim_args = {'weight_decay':0.2},\n",
    "                                  criterion=ptt.MPELoss(p=p),\n",
    "                                  old_best_loss = old_best_loss,\n",
    "                                  dispHead = 0, dispTail = 0)\n",
    "  tmp = test(model,ptt.MPELoss(p=p),train_data_loader)\n",
    "  if tmp > 1:\n",
    "    continue\n",
    "  mode,hist = ptt.train_supervised(model,2.0e-3,40,\n",
    "                                  train_data_loader,\n",
    "                                  optimizer=torch.optim.Adam,\n",
    "#                                   optim_args = {'weight_decay':0.2},\n",
    "                                  criterion=ptt.MPELoss(p=p),\n",
    "                                  old_hist = hist,\n",
    "                                  old_best_loss = old_best_loss,\n",
    "                                  dispHead = 0, dispTail = 0)\n",
    "  newloss = test(model,ptt.MPELoss(p=p),train_data_loader)\n",
    "  \n",
    "  if newloss < old_best_loss:\n",
    "    old_best_loss = newloss\n",
    "    final_model = copy(model)\n",
    "    final_hist  = copy(hist)\n",
    "    \n",
    "  if newloss < 1e-3:\n",
    "    break\n",
    "    \n",
    "  plt.figure(figsize=(4,2))\n",
    "  plt.semilogy(hist['train_loss'])\n",
    "\n",
    "\n",
    "model = final_model\n",
    "hist = final_hist\n",
    "mode,hist = ptt.train_supervised(model,5.0e-4,80,\n",
    "                                train_data_loader,\n",
    "                                optimizer=torch.optim.Adam,\n",
    "#                                 optim_args = {'weight_decay':0.2},\n",
    "                                criterion=ptt.MPELoss(p=p),\n",
    "                                old_hist = hist,\n",
    "                                old_best_loss = newloss,\n",
    "                                dispHead = 0, dispTail = 0)\n",
    "newloss = test(model,ptt.MPELoss(p=p),train_data_loader)\n",
    "\n",
    "\n",
    "model = model.cpu()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(hist['train_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    return model(torch.Tensor(x)).detach().numpy().flatten()\n",
    "\n",
    "y_train = f(x_train) -f1(x_train)\n",
    "\n",
    "y_test = f(x_test) -f1(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,4))\n",
    "\n",
    "plt.plot(x_onAxis[:,0],y_onAxis ,'k' , label='Ground Truth')\n",
    "plt.plot(x_onAxis[:,0],f0(x_onAxis),'r:', label='Prior',alpha=0.7)\n",
    "plt.plot(x_onAxis[:,0],f1(x_onAxis),'r', label='Data Driven Prior')\n",
    "plt.plot(x_onAxis[:,0],y_onAxis-f1(x_onAxis),'b:', label='Difference',alpha=0.5)\n",
    "\n",
    "\n",
    "plt.title('1D slice view of Prior')\n",
    "plt.xlabel(r'$x_0$')\n",
    "plt.ylabel(r'$f(x)$')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-0.4,1.2)\n",
    "plt.xticks([-1,-0.5,0,0.5,1])\n",
    "plt.savefig('DataDrivenPrior_'+str(d)+'D_SliceView.png',dpi=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = C(1.0, (1e-1, 10.0)) * RBF(1, (2e-2, 1.0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=3, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.score(x_train, y_train), gp.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.fit(x_train, y_train)\n",
    "gp.kernel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.score(x_train, y_train), gp.score(x_test, y_test)  \n",
    "# score over test data after train can become even worse when train data is not enough !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, sigma = gp.predict(x_onAxis, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(x_onAxis[:,0],y_onAxis           ,'k' , label='Ground Truth')\n",
    "ax.plot(x_onAxis[:,0],f1(x_onAxis)       ,'r',  label='Data Driven Prior')\n",
    "ax.plot(x_onAxis[:,0],f1(x_onAxis)+y_pred,'b-', label='Prediction')\n",
    "ax.fill_between(x_onAxis[:,0], \n",
    "                f1(x_onAxis)+y_pred- 1.96 * sigma,\n",
    "                f1(x_onAxis)+y_pred+ 1.96 * sigma, \n",
    "                label='95% confidence interval', color='C0', alpha=.5, )\n",
    "\n",
    "plt.title('1D slice view of '+str(d)+'D problem with data driven prior')\n",
    "plt.xlabel(r'$x_0$')\n",
    "plt.ylabel(r'$f(x)$')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-0.4,1.2)\n",
    "plt.xticks([-1,-0.5,0,0.5,1])\n",
    "plt.savefig('GP_wDataDrivenPrior_'+str(d)+'D_'+str(n)+'sample_'+str(nPrior)+'priorSample.png',dpi=180)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-v1.4.0",
   "language": "python",
   "name": "pytorch-v1.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
